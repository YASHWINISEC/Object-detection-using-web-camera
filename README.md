# Object-detection-using-web-camera

# üì∑ Real-Time Object Detection Using YOLOv4 and Webcam

## üß† Overview

This project demonstrates *real-time object detection* using the *YOLOv4* model on a webcam feed. It uses *OpenCV* to access your webcam and applies a deep learning model to detect and label objects live in each frame.

---

## üöÄ Features

- üéØ Real-time object detection with YOLOv4
- üì¶ Draws bounding boxes with labels and confidence scores
- üîç Detects multiple objects per frame
- üñ• Uses your webcam for live video input
- üõ† Easily customizable to use custom-trained models

---

## üìÅ Project Structure

object-detection-webcam/
‚îÇ

‚îú‚îÄ‚îÄ detect.py # Main detection script

‚îú‚îÄ‚îÄ yolov4.weights # Pre-trained YOLOv4 weights

‚îú‚îÄ‚îÄ yolov4.cfg # YOLOv4 configuration file

‚îú‚îÄ‚îÄ coco.names # COCO class labels (80 classes)

‚îú‚îÄ‚îÄ requirements.txt # Python dependencies

‚îî‚îÄ‚îÄ README.md # This README file


---

## üß∞ Requirements

- Python 3.x
- OpenCV
- NumPy

### üì¶ Install Dependencies

Using pip:

bash
pip install -r requirements.txt

# Download YOLOv4 Files

Download the following files and place them in the root folder:

yolov4.weights

yolov4.cfg

coco.names

How to Run

Make sure you have the necessary files, then run:

python detect.py


Press q to quit the program.

Detected objects will be labeled in the webcam feed.

üß™ How It Works

Capture frames from webcam with OpenCV.

Preprocess each frame to a blob suitable for YOLOv4.

Run inference using OpenCV's DNN module.

Post-process outputs:

Filter by confidence threshold (0.5).

Apply Non-Max Suppression to remove duplicates.

Display bounding boxes and class labels in real-time.

# code:
python

import cv2
import numpy as np

# Load YOLOv4 network
net = cv2.dnn.readNet("yolov4.weights", "yolov4.cfg")

# Load the COCO class labels
with open("coco.names", "r") as f:
    classes = [line.strip() for line in f.readlines()]

layer_names = net.getLayerNames()
output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers().flatten()]

# Set up video capture for webcam
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    height, width, channels = frame.shape

    # Prepare the image for YOLOv4
    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)
    net.setInput(blob)
    
    # Get YOLO output
    outputs = net.forward(output_layers)
    
    # Initialize lists to store detected boxes, confidences, and class IDs
    boxes = []
    confidences = []
    class_ids = []

    for output in outputs:
        for detection in output:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]
            if confidence > 0.5:
                # Object detected
                center_x = int(detection[0] * width)
                center_y = int(detection[1] * height)
                w = int(detection[2] * width)
                h = int(detection[3] * height)

                # Calculate top-left corner of the box
                x = int(center_x - w / 2)
                y = int(center_y - h / 2)

                boxes.append([x, y, w, h])
                confidences.append(float(confidence))
                class_ids.append(class_id)

    # Apply Non-Max Suppression to eliminate redundant overlapping boxes
    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)

    # Draw bounding boxes and labels on the image
    if len(indexes) > 0:
        for i in indexes.flatten():
            x, y, w, h = boxes[i]
            label = str(classes[class_ids[i]])
            confidence = confidences[i]

            color = (0, 255, 0)  # Green color for bounding boxes
            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
            cv2.putText(frame, f"{label} {confidence:.2f}", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # Show the image with detected objects
    cv2.imshow("YOLOv4 Real-Time Object Detection", frame)

    # Exit the loop if 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release video capture and close windows
cap.release()
cv2.destroyAllWindows()
 


üì∏ Example Output

Here's what the output looks like (example image):

![Uploading Screenshot 2025-09-20 145356.png‚Ä¶]()



üßæ Sample requirements.txt
opencv-python
numpy

# üõ† Troubleshooting

‚ùå Webcam not detected: Make sure it's not in use by another app.

‚ö† No objects detected: Ensure yolov4.weights, cfg, and coco.names are in the correct location.

üê¢ Too slow?: Lower the video resolution or switch to a smaller YOLO model (e.g., YOLOv4-tiny).

# üìÑ License

This project is licensed under the MIT License. See the LICENSE
 file for details.

# üôå Acknowledgments

YOLOv4 by Alexey Bochkovskiy

COCO Dataset

OpenCV



### ‚úÖ What to Do Next:
1. Save this content as README.md in your project folder.
2. Push your entire project folder (including detect.py, model files, and this README) to GitHub.

Let me know if you'd like me to generate a LICENSE file or a .gitignore too!
